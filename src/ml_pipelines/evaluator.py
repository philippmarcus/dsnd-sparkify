"""
author: Philipp Marcus
email: marcus@cip.ifi.lmu.de

Calculates various metrics for a trained CrossV
"""

from pyspark.ml.evaluation import MulticlassClassificationEvaluator


def evaluate_model(data_set, model_name = "unnamed", label_col='churn'):
    """
    Evaluates the f1, accuracy, precision and recall score on a given
    data set, assuming the columns 'churn' as label and 'prediction' for
    the value generated by the classificator.
    
    INPUT:
        `data_set` (DataFrame): Spark DataFrame that was processed by then `.transform(...)` method of the cv already.
        `model_name` (string): Name of the ML algorithm that was used to generate the results. Used in the ouput data.
        `label_col` (string): Name of the column in `data_set` that contains the labels.
    OUTPUT:
        - result (dict): keys are accuracy, recall, precision, f1. Values are provided as float.
    """
    # Extract the evaluator
    evaluator = MulticlassClassificationEvaluator(labelCol=label_col)

    # Calculate the metrics
    recall = evaluator.evaluate(data_set, {evaluator.metricName: "weightedRecall"})
    precision = evaluator.evaluate(data_set, {evaluator.metricName: "weightedPrecision"})
    accuracy = evaluator.evaluate(data_set, {evaluator.metricName: "accuracy"})
    f1 = evaluator.evaluate(data_set, {evaluator.metricName: "f1"})
    
    # Create a dict and return
    return {'model': model_name,
            'recall': recall,
            'precision': precision,
            'accuracy': accuracy,
            'f1': f1 } 